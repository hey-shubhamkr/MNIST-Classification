{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_data, mnist_info = tfds.load(\"mnist\",with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata,testdata= mnist_data[\"train\"],mnist_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = 0.1* mnist_info.splits[\"train\"].num_examples\n",
    "num_validation = tf.cast(num_validation,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = mnist_info.splits[\"test\"].num_examples\n",
    "num_test = tf.cast(num_test, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /=255.\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = traindata.map(scale)\n",
    "test_data = testdata.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffersize = 10000\n",
    "\n",
    "shuffled_data = train_and_validation_data.shuffle(buffersize)\n",
    "\n",
    "validation_data = shuffled_data.take(num_validation)\n",
    "train_data = shuffled_data.skip(num_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_data = train_data.batch(batch_size)\n",
    "validation_data = validation_data.batch(batch_size)\n",
    "test_data= test_data.batch(batch_size)\n",
    "\n",
    "validation_train, validation_test = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_layer_size = 50\n",
    "output_size = 10\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape= (28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation=\"relu\"),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation=\"relu\"),\n",
    "                            tf.keras.layers.Dense(output_size, activation=\"softmax\")\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.1208 - accuracy: 0.9639 - val_loss: 0.1184 - val_accuracy: 0.9700\n",
      "Epoch 2/5\n",
      "540/540 - 3s - loss: 0.1026 - accuracy: 0.9685 - val_loss: 0.1302 - val_accuracy: 0.9600\n",
      "Epoch 3/5\n",
      "540/540 - 3s - loss: 0.0888 - accuracy: 0.9731 - val_loss: 0.0985 - val_accuracy: 0.9700\n",
      "Epoch 4/5\n",
      "540/540 - 3s - loss: 0.0781 - accuracy: 0.9767 - val_loss: 0.1300 - val_accuracy: 0.9400\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0683 - accuracy: 0.9794 - val_loss: 0.0829 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e03f91e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "model.fit(train_data, epochs = num_epochs, validation_data = (validation_train, validation_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 3s 5ms/step - loss: 0.0538 - accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.05382893979549408 and accuracy of model is 98.4499990940094 \n"
     ]
    }
   ],
   "source": [
    "print(f\"loss is {train_loss} and accuracy of model is {train_accuracy*100} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
